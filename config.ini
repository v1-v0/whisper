[DEFAULT]
# Audio file path - leave empty to auto-detect from 'source' folder
audio_file = 

# Whisper model to use
# Options: tiny, base, small, medium, large, large-v2, large-v3, large-v3-turbo
# Note: For MLX, models are automatically converted to MLX format
# Recommended: large-v3 for best balance of speed and accuracy
whisper_model = large-v3

# Output directory for transcription files
output_dir = outputs

# Use MLX-Whisper for Apple Silicon Macs (recommended for better performance)
# Set to false to use standard OpenAI Whisper
use_mlx = true

# Force CPU usage (disable GPU/MPS acceleration)
# Set to true if you encounter GPU-related issues
force_cpu = false

# Hugging Face token file path (SECURE METHOD)
# The script will look for your HF token in this file
# This file will be created automatically if it doesn't exist
# Make sure to add this file to your .gitignore!
hf_token_file = .hf_token

# Language specification
# Leave empty for auto-detection, or specify language code to force a specific language
# Common codes: en (English), zh (Chinese), ja (Japanese), ko (Korean), 
#               es (Spanish), fr (French), de (German), it (Italian), etc.
# Full list: https://github.com/openai/whisper/blob/main/whisper/tokenizer.py
language = 

# Task type - IMPORTANT for maintaining original language
# transcribe: Maintains the original language of the audio (RECOMMENDED)
# translate: Translates everything to English
task = transcribe

[SECURITY]
# Security notes for Hugging Face authentication:
# 
# The script checks for HF tokens in the following order:
# 1. Environment variable: HF_TOKEN
# 2. Environment variable: HUGGING_FACE_HUB_TOKEN  
# 3. Token file specified in hf_token_file setting
# 4. Default token file: .hf_token
# 5. Existing HF CLI login (huggingface-cli login)
#
# RECOMMENDED METHODS:
# 
# Method 1 - Environment Variable (most secure for servers):
#   export HF_TOKEN="hf_your_token_here"
#   
# Method 2 - Token File (good for local development):
#   Put your token in the .hf_token file (created automatically)
#   Make sure .hf_token is in your .gitignore file!
#   
# Method 3 - HF CLI (convenient for interactive use):
#   Run: huggingface-cli login
#   
# NEVER put your token directly in this config file!

[ADVANCED]
# Initial prompt to improve transcription accuracy
# Useful for technical terms, names, or specific vocabulary
# Example: "This audio contains technical terminology about machine learning and AI."
initial_prompt = 

# Temperature for sampling (0.0 = deterministic, higher = more random)
# Range: 0.0 to 1.0
temperature = 0.0

# Beam size for beam search (higher = more accurate but slower)
# Range: 1 to 10, recommended: 5
beam_size = 5

# Enable word-level timestamps
word_timestamps = false

# Compression ratio threshold (helps detect repetitive outputs)
compression_ratio_threshold = 2.4

# Log probability threshold for segments
logprob_threshold = -1.0

# No speech threshold (helps detect silence)
no_speech_threshold = 0.6

[PROFILES]
# Different configuration profiles for various use cases

[FAST]
# Configuration for fast transcription (maintains original language)
whisper_model = base
use_mlx = true
force_cpu = false
task = transcribe

[ACCURATE]
# Configuration for highest accuracy (maintains original language)
whisper_model = large-v3
use_mlx = true
force_cpu = false
task = transcribe

[MULTILINGUAL]
# Configuration for non-English content (maintains original language)
whisper_model = large-v3
use_mlx = true
task = transcribe
initial_prompt = This audio contains technical terminology and proper names.

[CHINESE]
# Configuration specifically for Chinese audio
whisper_model = large-v3
use_mlx = true
language = zh
task = transcribe

[JAPANESE]
# Configuration specifically for Japanese audio
whisper_model = large-v3
use_mlx = true
language = ja
task = transcribe

[KOREAN]
# Configuration specifically for Korean audio
whisper_model = large-v3
use_mlx = true
language = ko
task = transcribe

[ENGLISH_ONLY]
# Configuration for English audio or to translate everything to English
whisper_model = large-v3
use_mlx = true
language = en
task = transcribe

[TRANSLATE_TO_ENGLISH]
# Configuration to translate any language to English
whisper_model = large-v3
use_mlx = true
task = translate