[DEFAULT]
# Audio file path - leave empty to auto-detect from 'source' folder
audio_file = 

# Whisper model to use
# Options: tiny, base, small, medium, large, large-v2, large-v3, large-v3-turbo
# Note: For MLX, models are automatically converted to MLX format
# Recommended: large-v3 for best balance of speed and accuracy
whisper_model = large-v3

# Output directory for transcription files
output_dir = outputs

# Use MLX-Whisper for Apple Silicon Macs (recommended for better performance)
# Set to false to use standard OpenAI Whisper
use_mlx = true

# Force CPU usage (disable GPU/MPS acceleration)
# Set to true if you encounter GPU-related issues
force_cpu = false

# Hugging Face token for accessing private models (optional)
# Get your token from: https://huggingface.co/settings/tokens
# Leave empty for public models only
hf_token = 

# Language specification
# Leave empty for auto-detection, or specify language code to force a specific language
# Common codes: en (English), zh (Chinese), ja (Japanese), ko (Korean), 
#               es (Spanish), fr (French), de (German), it (Italian), etc.
# Full list: https://github.com/openai/whisper/blob/main/whisper/tokenizer.py
language = 

# Task type - IMPORTANT for maintaining original language
# transcribe: Maintains the original language of the audio (RECOMMENDED)
# translate: Translates everything to English
task = translate

[ADVANCED]
# Initial prompt to improve transcription accuracy
# Useful for technical terms, names, or specific vocabulary
# Example: "This audio contains technical terminology about machine learning and AI."
initial_prompt = 

# Temperature for sampling (0.0 = deterministic, higher = more random)
# Range: 0.0 to 1.0
temperature = 0.0

# Beam size for beam search (higher = more accurate but slower)
# Range: 1 to 10, recommended: 5
beam_size = 5

# Enable word-level timestamps
word_timestamps = false

# Compression ratio threshold (helps detect repetitive outputs)
compression_ratio_threshold = 2.4

# Log probability threshold for segments
logprob_threshold = -1.0

# No speech threshold (helps detect silence)
no_speech_threshold = 0.6

[PROFILES]
# Different configuration profiles for various use cases

[FAST]
# Configuration for fast transcription (maintains original language)
whisper_model = base
use_mlx = true
force_cpu = false
task = transcribe

[ACCURATE]
# Configuration for highest accuracy (maintains original language)
whisper_model = large-v3
use_mlx = true
force_cpu = false
task = transcribe

[MULTILINGUAL]
# Configuration for non-English content (maintains original language)
whisper_model = large-v3
use_mlx = true
task = transcribe
initial_prompt = This audio contains technical terminology and proper names.

[CHINESE]
# Configuration specifically for Chinese audio
whisper_model = large-v3
use_mlx = true
language = zh
task = transcribe

[JAPANESE]
# Configuration specifically for Japanese audio
whisper_model = large-v3
use_mlx = true
language = ja
task = transcribe

[KOREAN]
# Configuration specifically for Korean audio
whisper_model = large-v3
use_mlx = true
language = ko
task = transcribe

[ENGLISH_ONLY]
# Configuration for English audio or to translate everything to English
whisper_model = large-v3
use_mlx = true
language = en
task = transcribe

[TRANSLATE_TO_ENGLISH]
# Configuration to translate any language to English
whisper_model = large-v3
use_mlx = true
task = translate